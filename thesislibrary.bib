@article{alaa_conformal_2023,
  title = {Conformal {{Meta-learners}} for {{Predictive Inference}} of {{Individual Treatment Effects}}},
  author = {Alaa, Ahmed and Ahmad, Zaid and van der Laan, Mark},
  options = {useprefix=true},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2308.14895},
  url = {https://arxiv.org/abs/2308.14895},
  urldate = {2024-01-03},
  abstract = {We investigate the problem of machine learning-based (ML) predictive inference on individual treatment effects (ITEs). Previous work has focused primarily on developing ML-based meta-learners that can provide point estimates of the conditional average treatment effect (CATE); these are model-agnostic approaches for combining intermediate nuisance estimates to produce estimates of CATE. In this paper, we develop conformal meta-learners, a general framework for issuing predictive intervals for ITEs by applying the standard conformal prediction (CP) procedure on top of CATE meta-learners. We focus on a broad class of meta-learners based on two-stage pseudo-outcome regression and develop a stochastic ordering framework to study their validity. We show that inference with conformal meta-learners is marginally valid if their (pseudo outcome) conformity scores stochastically dominate oracle conformity scores evaluated on the unobserved ITEs. Additionally, we prove that commonly used CATE meta-learners, such as the doubly-robust learner, satisfy a model- and distribution-free stochastic (or convex) dominance condition, making their conformal inferences valid for practically-relevant levels of target coverage. Whereas existing procedures conduct inference on nuisance parameters (i.e., potential outcomes) via weighted CP, conformal meta-learners enable direct inference on the target parameter (ITE). Numerical experiments show that conformal meta-learners provide valid intervals with competitive efficiency while retaining the favorable point estimation properties of CATE meta-learners.},
  version = {1},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/maxwell.marcos/Zotero/storage/GUNH9PFC/Alaa et al. - 2023 - Conformal Meta-learners for Predictive Inference o.pdf}
}

@article{athey_machine_2019,
  title = {Machine {{Learning Methods That Economists Should Know About}}},
  author = {Athey, Susan and Imbens, Guido W.},
  date = {2019-08-02},
  journaltitle = {Annual Review of Economics},
  shortjournal = {Annu. Rev. Econ.},
  volume = {11},
  number = {1},
  pages = {685--725},
  issn = {1941-1383, 1941-1391},
  doi = {10.1146/annurev-economics-080217-053433},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-economics-080217-053433},
  urldate = {2024-05-25},
  abstract = {We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models.},
  langid = {english}
}

@article{athey_recursive_2016,
  title = {Recursive {{Partitioning}} for {{Heterogeneous Causal Effects}}},
  author = {Athey, Susan and Imbens, Guido},
  date = {2016-07-05},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {113},
  number = {27},
  eprint = {1504.01132},
  eprinttype = {arxiv},
  eprintclass = {econ, stat},
  pages = {7353--7360},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1510489113},
  url = {http://arxiv.org/abs/1504.01132},
  urldate = {2023-12-25},
  abstract = {In this paper we study the problems of estimating heterogeneity in causal effects in experimental or observational studies and conducting inference about the magnitude of the differences in treatment effects across subsets of the population. In applications, our method provides a data-driven approach to determine which subpopulations have large or small treatment effects and to test hypotheses about the differences in these effects. For experiments, our method allows researchers to identify heterogeneity in treatment effects that was not specified in a pre-analysis plan, without concern about invalidating inference due to multiple testing. In most of the literature on supervised machine learning (e.g. regression trees, random forests, LASSO, etc.), the goal is to build a model of the relationship between a unit's attributes and an observed outcome. A prominent role in these methods is played by cross-validation which compares predictions to actual outcomes in test samples, in order to select the level of complexity of the model that provides the best predictive power. Our method is closely related, but it differs in that it is tailored for predicting causal effects of a treatment rather than a unit's outcome. The challenge is that the "ground truth" for a causal effect is not observed for any individual unit: we observe the unit with the treatment, or without the treatment, but not both at the same time. Thus, it is not obvious how to use cross-validation to determine whether a causal effect has been accurately predicted. We propose several novel cross-validation criteria for this problem and demonstrate through simulations the conditions under which they perform better than standard methods for the problem of causal effects. We then apply the method to a large-scale field experiment re-ranking results on a search engine.},
  keywords = {TR(2)},
  file = {/Users/maxwell.marcos/Zotero/storage/AZKWKP36/Athey e Imbens - 2016 - Recursive Partitioning for Heterogeneous Causal Ef.pdf;/Users/maxwell.marcos/Zotero/storage/W63A4JBH/1504.html}
}

@online{blog_post,
  title = {The {{MineThatData}} E-Mail Analytics and Data Mining Challenge.},
  author = {Kevin Hillstrom},
  date = {2008},
  url = {https://blog.minethatdata.com/2008/03/minethatdata-e-mail-analytics-and-data.html}
}

@article{cheng_causal_2021,
  title = {Causal {{Learning}} for {{Socially Responsible AI}}},
  author = {Cheng, Lu and Mosallanezhad, Ahmadreza and Sheth, Paras and Liu, Huan},
  date = {2021},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2104.12278},
  url = {https://arxiv.org/abs/2104.12278},
  urldate = {2024-01-05},
  abstract = {There have been increasing concerns about Artificial Intelligence (AI) due to its unfathomable potential power. To make AI address ethical challenges and shun undesirable outcomes, researchers proposed to develop socially responsible AI (SRAI). One of these approaches is causal learning (CL). We survey state-of-the-art methods of CL for SRAI. We begin by examining the seven CL tools to enhance the social responsibility of AI, then review how existing works have succeeded using these tools to tackle issues in developing SRAI such as fairness. The goal of this survey is to bring forefront the potentials and promises of CL for SRAI.},
  version = {2},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences},
  file = {/Users/maxwell.marcos/Zotero/storage/XN48U8Q7/Cheng et al. - 2021 - Causal Learning for Socially Responsible AI.pdf}
}

@online{chernozhukov_applied_2024,
  title = {Applied {{Causal Inference Powered}} by {{ML}} and {{AI}}},
  author = {Chernozhukov, Victor and Hansen, Christian and Kallus, Nathan and Spindler, Martin and Syrgkanis, Vasilis},
  date = {2024},
  doi = {10.48550/ARXIV.2403.02467},
  url = {https://arxiv.org/abs/2403.02467},
  urldate = {2024-05-25},
  abstract = {An introduction to the emerging fusion of machine learning and causal inference. The book presents ideas from classical structural equation models (SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and structural causal models (SCMs), and covers Double/Debiased Machine Learning methods to do inference in such models using modern predictive tools.},
  pubstate = {preprint},
  version = {1},
  keywords = {Econometrics (econ.EM),FOS: Computer and information sciences,FOS: Economics and business,Machine Learning (cs.LG),Machine Learning (stat.ML),Methodology (stat.ME)}
}

@article{chernozhukov_automatic_2022,
  title = {Automatic {{Debiased Machine Learning}} of {{Causal}} and {{Structural Effects}}},
  author = {Chernozhukov, Victor and Newey, Whitney K. and Singh, Rahul},
  date = {2022},
  journaltitle = {Econometrica},
  shortjournal = {ECTA},
  volume = {90},
  number = {3},
  pages = {967--1027},
  issn = {0012-9682},
  doi = {10.3982/ECTA18515},
  url = {https://www.econometricsociety.org/doi/10.3982/ECTA18515},
  urldate = {2023-12-25},
  abstract = {Many causal and structural effects depend on regressions. Examples include policy effects, average derivatives, regression decompositions, average treatment effects, causal mediation, and parameters of economic structural models. The regressions may be high-dimensional, making machine learning useful. Plugging machine learners into identifying equations can lead to poor inference due to bias from regularization and/or model selection. This paper gives automatic debiasing for linear and nonlinear functions of regressions. The debiasing is automatic in using Lasso and the function of interest without the full form of the bias correction. The debiasing can be applied to any regression learner, including neural nets, random forests, Lasso, boosting, and other high-dimensional methods. In addition to providing the bias correction, we give standard errors that are robust to misspecification, convergence rates for the bias correction, and primitive conditions for asymptotic inference for estimators of a variety of estimators of structural and causal effects. The automatic debiased machine learning is used to estimate the average treatment effect on the treated for the NSW job training data and to estimate demand elasticities from Nielsen scanner data while allowing preferences to be correlated with prices and income.},
  langid = {english},
  keywords = {TR ()},
  file = {/Users/maxwell.marcos/Zotero/storage/WBC5Z4TW/Chernozhukov et al. - 2022 - Automatic Debiased Machine Learning of Causal and .pdf}
}

@online{chernozhukov_doubledebiased_2016,
  title = {Double/{{Debiased Machine Learning}} for {{Treatment}} and {{Causal Parameters}}},
  author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
  date = {2016},
  doi = {10.48550/ARXIV.1608.00060},
  url = {https://arxiv.org/abs/1608.00060},
  urldate = {2024-05-25},
  abstract = {Most modern supervised statistical/machine learning (ML) methods are explicitly designed to solve prediction problems very well. Achieving this goal does not imply that these methods automatically deliver good estimators of causal parameters. Examples of such parameters include individual regression coefficients, average treatment effects, average lifts, and demand or supply elasticities. In fact, estimates of such causal parameters obtained via naively plugging ML estimators into estimating equations for such parameters can behave very poorly due to the regularization bias. Fortunately, this regularization bias can be removed by solving auxiliary prediction problems via ML tools. Specifically, we can form an orthogonal score for the target low-dimensional parameter by combining auxiliary and main ML predictions. The score is then used to build a de-biased estimator of the target parameter which typically will converge at the fastest possible 1/root(n) rate and be approximately unbiased and normal, and from which valid confidence intervals for these parameters of interest may be constructed. The resulting method thus could be called a "double ML" method because it relies on estimating primary and auxiliary predictive models. In order to avoid overfitting, our construction also makes use of the K-fold sample splitting, which we call cross-fitting. This allows us to use a very broad set of ML predictive methods in solving the auxiliary and main prediction problems, such as random forest, lasso, ridge, deep neural nets, boosted trees, as well as various hybrids and aggregators of these methods.},
  pubstate = {preprint},
  version = {6},
  keywords = {62G,Econometrics (econ.EM),FOS: Computer and information sciences,FOS: Economics and business,Machine Learning (stat.ML)}
}

@article{cole_consistency_2009,
  title = {The {{Consistency Statement}} in {{Causal Inference}}: {{A Definition}} or an {{Assumption}}?},
  shorttitle = {The {{Consistency Statement}} in {{Causal Inference}}},
  author = {Cole, Stephen R. and Frangakis, Constantine E.},
  date = {2009-01},
  journaltitle = {Epidemiology},
  volume = {20},
  number = {1},
  pages = {3--5},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e31818ef366},
  url = {https://journals.lww.com/00001648-200901000-00003},
  urldate = {2024-03-18},
  langid = {english}
}

@article{coleConsistencyStatementCausal2009,
  title = {The {{Consistency Statement}} in {{Causal Inference}}: {{A Definition}} or an {{Assumption}}?},
  shorttitle = {The {{Consistency Statement}} in {{Causal Inference}}},
  author = {Cole, Stephen R. and Frangakis, Constantine E.},
  date = {2009-01},
  journaltitle = {Epidemiology},
  volume = {20},
  number = {1},
  pages = {3--5},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e31818ef366},
  url = {https://journals.lww.com/00001648-200901000-00003},
  urldate = {2024-02-06},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/9MNCBWG8/Cole e Frangakis - 2009 - The Consistency Statement in Causal Inference A D.pdf}
}

@book{cunningham_causal_2021,
  title = {Causal Inference: The Mixtape},
  shorttitle = {Causal Inference},
  author = {Cunningham, Scott},
  date = {2021},
  publisher = {Yale University Press},
  location = {New Haven ; London},
  abstract = {An accessible and contemporary introduction to the methods for determining cause and effect in the social sciences Causal inference encompasses the tools that allow social scientists to determine what causes what. Economists--who generally can't run controlled experiments to test and validate their hypotheses--apply these tools to observational data to make connections. In a messy world, causal inference is what helps establish the causes and effects of the actions being studied, whether the impact (or lack thereof) of increases in the minimum wage on employment, the effects of early childhood education on incarceration later in life, or the introduction of malaria nets in developing regions on economic growth. Scott Cunningham introduces students and practitioners to the methods necessary to arrive at meaningful answers to the questions of causation, using a range of modeling techniques and coding instructions for both the R and Stata programming languages. - -},
  isbn = {978-0-300-25168-5},
  pagetotal = {572},
  keywords = {BUSINESS & ECONOMICS / Econometrics,Causation,Data processing,Dependence (Statistics),Inference,Methodology,Social sciences},
  annotation = {OCLC: on1146568673}
}

@article{damour_overlap_2021,
  title = {Overlap in Observational Studies with High-Dimensional Covariates},
  author = {D'Amour, Alexander and Ding, Peng and Feller, Avi and Lei, Lihua and Sekhon, Jasjeet},
  date = {2021-04},
  journaltitle = {Journal of Econometrics},
  shortjournal = {Journal of Econometrics},
  volume = {221},
  number = {2},
  pages = {644--654},
  issn = {03044076},
  doi = {10.1016/j.jeconom.2019.10.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407620302694},
  urldate = {2024-03-03},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/7HSA8SE8/D’Amour et al. - 2021 - Overlap in observational studies with high-dimensi.pdf;/Users/maxwell.marcos/Zotero/storage/LT2EBJEK/D’Amour et al. - 2021 - Overlap in observational studies with high-dimensi.pdf}
}

@book{facure_causal_2023,
  title = {Causal Inference in {{Python}}: Applying {{Causal Inference}} in the {{Tech Industry}}},
  shorttitle = {Causal Inference in {{Python}}},
  author = {Facure, Matheus},
  date = {2023},
  edition = {First Edition},
  publisher = {O'Reilly},
  location = {Beijing Boston Farnham Sebastopol Tokyo},
  abstract = {In this book, author Matheus Facure explains the untapped potential of causal inference for estimating impacts and effects},
  isbn = {978-1-09-814025-0},
  langid = {english},
  pagetotal = {385},
  file = {/Users/maxwell.marcos/Zotero/storage/ATER82ZY/Facure - 2023 - Causal inference in Python applying Causal Infere.pdf}
}

@article{fernandez-loria_causal_nodate,
  title = {Causal Classification : {{Treatment Effect Estimation}} vs. {{Outcome Prediction}}},
  author = {Fernandez-Lor\i a, Carlos and Provost, Foster},
  abstract = {The goal of causal classification is to identify individuals whose outcome would be positively changed by a treatment. Examples include targeting advertisements and targeting retention incentives to reduce churn. Causal classification is challenging because we observe individuals under only one condition (treated or untreated), so we do not know who was influenced by the treatment, but we may estimate the potential outcomes under each condition to decide whom to treat by estimating treatment effects. Curiously, we often see practitioners using simple outcome prediction instead, for example, predicting if someone will purchase if shown the ad. Rather than disregarding this as naive behavior, we present a theoretical analysis comparing treatment effect estimation and outcome prediction when addressing causal classification. We focus on the key question: ``When (if ever) is simple outcome prediction preferable to treatment effect estimation for causal classification?'' The analysis reveals a causal bias--variance tradeoff. First, when the treatment effect estimation depends on two outcome predictions, larger sampling variance may lead to more errors than the (biased) outcome prediction approach. Second, a stronger signal-to-noise ratio in outcome prediction implies that the bias can help with intervention decisions when outcomes are informative of effects. The theoretical results, as well as simulations, illustrate settings where outcome prediction should actually be better, including cases where (1) the bias may be partially corrected by choosing a different threshold, (2) outcomes and treatment effects are correlated, and (3) data to estimate counterfactuals are limited. A major practical implication is that, for some applications, it might be feasible to make good intervention decisions without any data on how individuals actually behave when intervened. Finally, we show that for a real online advertising application, outcome prediction models indeed excel at causal classification.},
  langid = {english},
  keywords = {TR ()},
  file = {/Users/maxwell.marcos/Zotero/storage/5RA388L3/Fernandez-Lorıa e Provost - Causal classification.pdf}
}

@article{feuerriegel_causal_2024,
  title = {Causal Machine Learning for Predicting Treatment Outcomes},
  author = {Feuerriegel, Stefan and Frauen, Dennis and Melnychuk, Valentyn and Schweisthal, Jonas and Hess, Konstantin and Curth, Alicia and Bauer, Stefan and Kilbertus, Niki and Kohane, Isaac S. and Van Der Schaar, Mihaela},
  date = {2024-04},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {30},
  number = {4},
  pages = {958--968},
  issn = {1078-8956, 1546-170X},
  doi = {10.1038/s41591-024-02902-1},
  url = {https://www.nature.com/articles/s41591-024-02902-1},
  urldate = {2024-05-07},
  langid = {english}
}

@book{fisher_design_1935,
  title = {The Design of Experiments.},
  author = {Fisher, R. A.},
  date = {1935},
  series = {The Design of Experiments.},
  pages = {xi, 251},
  publisher = {Oliver \& Boyd},
  location = {Oxford,  England},
  abstract = {Different types of experimentation are considered with reference to their logical structure, to show that valid conclusions may be drawn from them without using the disputed theory of inductive inferences, i.e., of arguing from observation to explanatory theory. This is possible if a null hypothesis is explicitly formulated when the experiment is designed; this hypothesis can never be proved, but may be disproved with whatever probability one will accept as demonstrating a positive result. Chapters II, III, and IV illustrate simple applications of the principles involved in sensitiveness, significance, tests of wider hypotheses, validity, and estimation and elimination of error. More elaborate structures are treated in later chapters. Chapter titles are: (V) the Latin square; (VI) factorial design in experimentation; (VII) confounding; (VIII) special cases of partial confounding; (IX) increase of precision by concomitant measurements: statistical control; (X) generalization of null hypotheses: fiducial probability; (XI) measurement of amount of information in general. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  pagetotal = {xi, 251}
}

@incollection{fisher_statistical_1992,
  title = {Statistical {{Methods}} for {{Research Workers}}},
  booktitle = {Breakthroughs in {{Statistics}}: {{Methodology}} and {{Distribution}}},
  author = {Fisher, R. A.},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  date = {1992},
  pages = {66--70},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4612-4380-9_6},
  url = {https://doi.org/10.1007/978-1-4612-4380-9_6},
  abstract = {The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.},
  isbn = {978-1-4612-4380-9}
}

@online{fuhr_estimating_2024,
  title = {Estimating {{Causal Effects}} with {{Double Machine Learning}} -- {{A Method Evaluation}}},
  author = {Fuhr, Jonathan and Berens, Philipp and Papies, Dominik},
  date = {2024-03-21},
  eprint = {2403.14385},
  eprinttype = {arxiv},
  eprintclass = {cs, econ, stat},
  url = {http://arxiv.org/abs/2403.14385},
  urldate = {2024-03-25},
  abstract = {The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal structure and identification. When estimating the effects of air pollution on housing prices in our application, we find that DML estimates are consistently larger than estimates of less flexible methods. From our overall results, we provide actionable recommendations for specific choices researchers must make when applying DML in practice.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Economics - Econometrics,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/maxwell.marcos/Zotero/storage/A6WFVF47/Fuhr et al. - 2024 - Estimating Causal Effects with Double Machine Lear.pdf;/Users/maxwell.marcos/Zotero/storage/69ERY83H/2403.html}
}

@thesis{galagate_causal_2016,
  title = {{{CAUSAL INFERENCE WITH A CONTINUOUS TREATMENT AND OUTCOME}}: {{ALTERNATIVE ESTIMATORS FOR PARAMETRIC DOSE-RESPONSE FUNCTIONS WITH APPLICATIONS}}.},
  shorttitle = {{{CAUSAL INFERENCE WITH A CONTINUOUS TREATMENT AND OUTCOME}}},
  author = {Galagate, Douglas},
  date = {2016},
  institution = {Digital Repository at the University of Maryland},
  doi = {10.13016/M2Q48K},
  url = {http://drum.lib.umd.edu/handle/1903/18170},
  urldate = {2023-12-25},
  abstract = {Causal inference with a continuous treatment is a relatively under-explored problem.  In this dissertation, we adopt the potential outcomes framework.  Potential outcomes are responses that would be seen for a unit under all possible treatments. In an observational study where the treatment is continuous, the potential outcomes are an uncountably infinite set indexed by treatment dose. We parameterize this unobservable set as a linear combination of a finite number of basis functions whose coefficients vary across units. This leads to new techniques for estimating the population average dose-response function (ADRF). Some techniques require a model for the treatment assignment given covariates, some require a model for predicting the potential outcomes from covariates, and some require both. We develop these techniques using a framework of estimating functions, compare them to existing methods for continuous treatments, and simulate their performance in a population where the ADRF is linear and the models for the treatment and/or outcomes may be misspecified.  We also extend the comparisons to a data set of lottery winners in Massachusetts.  Next, we describe the methods and functions in the R package causaldrf using data from the National Medical Expenditure Survey (NMES) and Infant Health and Development Program (IHDP) as examples.  Additionally, we analyze the National Growth and Health Study (NGHS) data set and deal with the issue of missing data.  Lastly, we discuss future research goals and possible extensions.},
  langid = {english},
  keywords = {TR(1)},
  file = {/Users/maxwell.marcos/Zotero/storage/8DR9QHHS/Galagate - 2016 - CAUSAL INFERENCE WITH A CONTINUOUS TREATMENT AND O.pdf}
}

@article{gauss_c_f_theoria_1809,
  title = {Theoria Motus Corporum Coelestum},
  author = {{GAUSS C. F.}},
  date = {1809},
  journaltitle = {Werke},
  url = {https://cir.nii.ac.jp/crid/1573950399668535168}
}

@article{goldsmith-pinkham_social_2013,
  title = {Social {{Networks}} and the {{Identification}} of {{Peer Effects}}},
  author = {Goldsmith-Pinkham, Paul and Imbens, Guido W.},
  date = {2013-07},
  journaltitle = {Journal of Business \& Economic Statistics},
  shortjournal = {Journal of Business \& Economic Statistics},
  volume = {31},
  number = {3},
  pages = {253--264},
  issn = {0735-0015, 1537-2707},
  doi = {10.1080/07350015.2013.801251},
  url = {http://www.tandfonline.com/doi/abs/10.1080/07350015.2013.801251},
  urldate = {2024-03-24},
  langid = {english}
}

@article{gutierrez_causal_nodate,
  title = {Causal {{Inference}} and {{Uplift Modeling A}} Review of the Literature},
  author = {Gutierrez, Pierre and Gerardy, Jean-Yves},
  abstract = {Uplift modeling refers to the set of techniques used to model the incremental impact of an action or treatment on a customer outcome. Uplift modeling is therefore both a Causal Inference problem and a Machine Learning one. The literature on uplift is split into 3 main approaches--the Two-Model approach, the Class Transformation approach and modeling uplift directly. Unfortunately, in the absence of a common framework of causal inference and notation, it can be quite di cult to assess those three methods. In this paper, we use the Rubin (1974) model of causal inference and its modern ``econometrics'' notation to provide a clear comparison of the three approaches and generalize one of them. To our knowledge, this is the first paper that provides a unified review of the uplift literature. Moreover, our paper contributes to the literature by showing that, in the limit, minimizing the Mean Square Error (MSE) formula with respect to a causal e↵ect estimator is equivalent to minimizing the MSE in which the unobserved treatment e↵ect is replaced by a modified target variable. Finally, we hope that our paper will be of use to researchers interested in applying Machine Learning techniques to causal inference problems in a business context as well as in other fields: medicine, sociology or economics.},
  langid = {english},
  keywords = {TR()},
  file = {/Users/maxwell.marcos/Zotero/storage/QYCCIV84/Gutierrez e Gerardy - Causal Inference and Uplift Modeling A review of t.pdf}
}

@inproceedings{han_bayesian_2018,
  title = {A {{Bayesian LSTM Model}} to {{Evaluate}} the {{Effects}} of {{Air Pollution Control Regulations}} in {{China}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Han, Yang and Lam, Jacqueline C.K. and Li, Victor O.K.},
  date = {2018-12},
  pages = {4465--4468},
  publisher = {IEEE},
  location = {Seattle, WA, USA},
  doi = {10.1109/BigData.2018.8622417},
  url = {https://ieeexplore.ieee.org/document/8622417/},
  urldate = {2024-04-20},
  eventtitle = {2018 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  isbn = {978-1-5386-5035-6},
  file = {/Users/maxwell.marcos/Zotero/storage/9WGT83RE/Han et al. - 2018 - A Bayesian LSTM Model to Evaluate the Effects of A.pdf}
}

@article{hansotia_incremental_2002,
  title = {Incremental Value Modeling},
  author = {Hansotia, Behram and Rukstales, Brad},
  date = {2002-08},
  journaltitle = {Journal of Interactive Marketing},
  shortjournal = {Journal of Interactive Marketing},
  volume = {16},
  number = {3},
  pages = {35--46},
  issn = {1094-9968, 1520-6653},
  doi = {10.1002/dir.10035},
  url = {http://journals.sagepub.com/doi/10.1002/dir.10035},
  urldate = {2024-05-28},
  langid = {english}
}

@article{hernan_does_2008,
  title = {Does Obesity Shorten Life? {{The}} Importance of Well-Defined Interventions to Answer Causal Questions},
  shorttitle = {Does Obesity Shorten Life?},
  author = {Hern\'an, M A and Taubman, S L},
  date = {2008-08},
  journaltitle = {International Journal of Obesity},
  shortjournal = {Int J Obes},
  volume = {32},
  number = {S3},
  pages = {S8-S14},
  issn = {0307-0565, 1476-5497},
  doi = {10.1038/ijo.2008.82},
  url = {https://www.nature.com/articles/ijo200882},
  urldate = {2024-03-18},
  langid = {english}
}

@article{hernanCompoundTreatmentsTransportability2011,
  title = {Compound {{Treatments}} and {{Transportability}} of {{Causal Inference}}},
  author = {Hern\'an, Miguel A. and VanderWeele, Tyler J.},
  date = {2011-05},
  journaltitle = {Epidemiology},
  volume = {22},
  number = {3},
  pages = {368--377},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e3182109296},
  url = {https://journals.lww.com/00001648-201105000-00018},
  urldate = {2024-02-07},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/4B2JJMNZ/Hernán e VanderWeele - 2011 - Compound Treatments and Transportability of Causal.pdf;/Users/maxwell.marcos/Zotero/storage/UVYPB9XF/Hernán e VanderWeele - 2011 - Compound Treatments and Transportability of Causal.pdf}
}

@inproceedings{hohnhold_focusing_2015,
  title = {Focusing on the {{Long-term}}: {{It}}'s {{Good}} for {{Users}} and {{Business}}},
  shorttitle = {Focusing on the {{Long-term}}},
  booktitle = {Proceedings of the 21th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Hohnhold, Henning and O'Brien, Deirdre and Tang, Diane},
  date = {2015-08-10},
  pages = {1849--1858},
  publisher = {ACM},
  location = {Sydney NSW Australia},
  doi = {10.1145/2783258.2788583},
  url = {https://dl.acm.org/doi/10.1145/2783258.2788583},
  urldate = {2024-03-24},
  eventtitle = {{{KDD}} '15: {{The}} 21th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-3664-2},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/N75DB2LG/Hohnhold et al. - 2015 - Focusing on the Long-term It's Good for Users and.pdf}
}

@article{holland_statistics_1986,
  title = {Statistics and {{Causal Inference}}},
  author = {Holland, Paul W.},
  date = {1986-12},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {81},
  number = {396},
  pages = {945--960},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1986.10478354},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478354},
  urldate = {2024-02-25},
  langid = {english}
}

@article{hortaDigitalFoodEnvironment2021,
  title = {Digital Food Environment of a {{Brazilian}} Metropolis: Food Availability and Marketing Strategies Used by Delivery Apps},
  shorttitle = {Digital Food Environment of a {{Brazilian}} Metropolis},
  author = {Horta, Paula Martins and Souza, Juliana De Paula Matos and Rocha, Luana Lara and Mendes, Larissa Loures},
  date = {2021-02},
  journaltitle = {Public Health Nutrition},
  shortjournal = {Public Health Nutr.},
  volume = {24},
  number = {3},
  pages = {544--548},
  issn = {1368-9800, 1475-2727},
  doi = {10.1017/S1368980020003171},
  url = {https://www.cambridge.org/core/product/identifier/S1368980020003171/type/journal_article},
  urldate = {2024-02-14},
  abstract = {Abstract                            Objective:               Food delivery apps represent an important and emerging dimension of the digital food environment. This study aimed to examine food availability and the use of marketing strategies by two food delivery apps in a Brazilian metropolis.                                         Design:               An exploratory study was conducted in the city of Belo Horizonte, Minas Gerais. Food groups were identified and the use of price discounts and photos by the apps was observed.                                         Setting:               Eighteen neighbourhoods and the ten best rated restaurants in each app.                                         Participants:               Three hundred sixty-two commercial food establishments.                                         Results:               The proportion of ultra-processed beverages on offer in the apps (78{$\cdot$}45 \%) was much higher in comparison with water (48{$\cdot$}89 \%), natural juices or smoothies (27{$\cdot$}07 \%). Ultra-processed ready-to-eat meals represented almost 70 \% of the food offered in the establishments' menus, while traditional meals and vegetables represented just over 30 \% of the offering. Ice cream, candies and salty packaged snacks were nine times more frequently presented than fruits. The use of photos and price discounts prevailed predominantly among ultra-processed beverages, sandwiches and ice cream, candies and salty packaged snacks. These marketing strategies were least used for promoting fruits and vegetables.                                         Conclusions:               Restaurants registered on food delivery apps offered a significant amount of ultra-processed foods with price discounts and photos in comparison with unprocessed and minimally processed foods.},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/LCF6QG59/Horta et al. - 2021 - Digital food environment of a Brazilian metropolis.pdf}
}

@book{huber_causal_2023,
  title = {Causal Analysis: Impact Evaluation and Causal Machine Learning with Applications in {{R}}},
  shorttitle = {Causal Analysis},
  author = {Huber, Martin},
  date = {2023},
  publisher = {The MIT Press},
  location = {Cambridge, Massachusetts London, England},
  abstract = {"A graduate-level textbook for causal inference/causal analysis in economics/econometrics courses"},
  isbn = {978-0-262-54591-4},
  langid = {english},
  pagetotal = {320},
  file = {/Users/maxwell.marcos/Zotero/storage/DK55ECPH/Huber - 2023 - Causal analysis impact evaluation and causal mach.pdf}
}

@article{hudgens_toward_2008,
  title = {Toward {{Causal Inference With Interference}}},
  author = {Hudgens, Michael G and Halloran, M. Elizabeth},
  date = {2008-06-01},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {103},
  number = {482},
  pages = {832--842},
  issn = {0162-1459, 1537-274X},
  doi = {10.1198/016214508000000292},
  url = {https://www.tandfonline.com/doi/full/10.1198/016214508000000292},
  urldate = {2024-03-24},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/8UQPY7IB/Hudgens e Halloran - 2008 - Toward Causal Inference With Interference.pdf}
}

@book{hume_enquiry_1993,
  title = {An Enquiry Concerning Human Understanding},
  author = {Hume, David and Steinberg, Eric},
  date = {1993},
  edition = {2. ed},
  publisher = {Hackett},
  location = {Indianapolis},
  isbn = {978-0-87220-229-0},
  langid = {english},
  pagetotal = {142}
}

@book{hume_letter_1745,
  title = {A Letter from a Gentleman to His Friend in {{Edinburgh}} (1745)},
  author = {Hume, David},
  date = {1745},
  publisher = {Edinburgh University Press}
}

@online{kaddour_causal_2022,
  title = {Causal {{Machine Learning}}: {{A Survey}} and {{Open Problems}}},
  shorttitle = {Causal {{Machine Learning}}},
  author = {Kaddour, Jean and Lynch, Aengus and Liu, Qi and Kusner, Matt J. and Silva, Ricardo},
  date = {2022-07-21},
  eprint = {2206.15475},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2206.15475},
  urldate = {2023-12-25},
  abstract = {Causal Machine Learning (CausalML) is an umbrella term for machine learning methods that formalize the data-generation process as a structural causal model (SCM). This perspective enables us to reason about the effects of changes to this process (interventions) and what would have happened in hindsight (counterfactuals). We categorize work in CausalML into five groups according to the problems they address: (1) causal supervised learning, (2) causal generative modeling, (3) causal explanations, (4) causal fairness, and (5) causal reinforcement learning. We systematically compare the methods in each category and point out open problems. Further, we review data-modality-specific applications in computer vision, natural language processing, and graph representation learning. Finally, we provide an overview of causal benchmarks and a critical discussion of the state of this nascent field, including recommendations for future work.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Methodology},
  file = {/Users/maxwell.marcos/Zotero/storage/EKP4Q2MR/Kaddour et al. - 2022 - Causal Machine Learning A Survey and Open Problem.pdf;/Users/maxwell.marcos/Zotero/storage/APDJHZEL/2206.html}
}

@inproceedings{kohavi_trustworthy_2012,
  title = {Trustworthy Online Controlled Experiments: Five Puzzling Outcomes Explained},
  shorttitle = {Trustworthy Online Controlled Experiments},
  booktitle = {Proceedings of the 18th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Kohavi, Ron and Deng, Alex and Frasca, Brian and Longbotham, Roger and Walker, Toby and Xu, Ya},
  date = {2012-08-12},
  pages = {786--794},
  publisher = {ACM},
  location = {Beijing China},
  doi = {10.1145/2339530.2339653},
  url = {https://dl.acm.org/doi/10.1145/2339530.2339653},
  urldate = {2024-03-24},
  eventtitle = {{{KDD}} '12: {{The}} 18th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-1462-6},
  langid = {english}
}

@book{kohavi_trustworthy_2020,
  title = {Trustworthy Online Controlled Experiments: A Practical Guide to {{A}}/{{B}} Testing},
  shorttitle = {Trustworthy Online Controlled Experiments},
  author = {Kohavi, Ron and Tang, Diane and Xu, Ya},
  date = {2020},
  publisher = {Cambridge University Press},
  location = {Cambridge, United Kingdom ; New York, NY},
  abstract = {"Getting numbers is easy; getting numbers you can trust is hard. This practical guide by experimentation leaders at Google, LinkedIn, and Microsoft will teach you how to accelerate innovation using trustworthy online controlled experiments, or A/B tests. Based on practical experiences at companies that each runs more than 20,000 controlled experiments a year, the authors share examples, pitfalls, and advice for students and industry professionals getting started with experiments, plus deeper dives into advanced topics for experienced practitioners who want to improve the way they and their organizations make data-driven decisions"--},
  isbn = {978-1-108-72426-5},
  keywords = {Social aspects,Social media,User-generated content}
}

@article{kunzel_metalearners_2019,
  title = {Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning},
  author = {K\"unzel, S\"oren R. and Sekhon, Jasjeet S. and Bickel, Peter J. and Yu, Bin},
  date = {2019-03-05},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {116},
  number = {10},
  pages = {4156--4165},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1804597116},
  url = {https://pnas.org/doi/full/10.1073/pnas.1804597116},
  urldate = {2023-12-26},
  abstract = {Significance             Estimating and analyzing heterogeneous treatment effects is timely, yet challenging. We introduce a unifying framework for many conditional average treatment effect estimators, and we propose a metalearner, the X-learner, which can adapt to structural properties, such as the smoothness and sparsity of the underlying treatment effect. We present its favorable properties, using theory and simulations. We apply it, using random forests, to two field experiments in political science, where it is shown to be easy to use and to produce results that are interpretable.           ,              There is growing interest in estimating and analyzing heterogeneous treatment effects in experimental and observational studies. We describe a number of metaalgorithms that can take advantage of any supervised learning or regression method in machine learning and statistics to estimate the conditional average treatment effect (CATE) function. Metaalgorithms build on base algorithms---such as random forests (RFs), Bayesian additive regression trees (BARTs), or neural networks---to estimate the CATE, a function that the base algorithms are not designed to estimate directly. We introduce a metaalgorithm, the X-learner, that is provably efficient when the number of units in one treatment group is much larger than in the other and can exploit structural properties of the CATE function. For example, if the CATE function is linear and the response functions in treatment and control are Lipschitz-continuous, the X-learner can still achieve the parametric rate under regularity conditions. We then introduce versions of the X-learner that use RF and BART as base learners. In extensive simulation studies, the X-learner performs favorably, although none of the metalearners is uniformly the best. In two persuasion field experiments from political science, we demonstrate how our X-learner can be used to target treatment regimes and to shed light on underlying mechanisms. A software package is provided that implements our methods.},
  langid = {english},
  keywords = {TR(3)},
  file = {/Users/maxwell.marcos/Zotero/storage/34R964LG/Künzel et al. - 2019 - Metalearners for estimating heterogeneous treatmen.pdf;/Users/maxwell.marcos/Zotero/storage/WWAGCHQ6/Künzel et al. - 2019 - Metalearners for estimating heterogeneous treatmen.pdf}
}

@article{lanza_causal_2013,
  title = {Causal {{Inference}} in {{Latent Class Analysis}}},
  author = {Lanza, Stephanie T. and Coffman, Donna L. and Xu, Shu},
  date = {2013-07-01},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {20},
  number = {3},
  pages = {361--383},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2013.797816},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2013.797816},
  urldate = {2024-03-18},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/JSB9ARRN/Lanza et al. - 2013 - Causal Inference in Latent Class Analysis.pdf}
}

@article{madden_causal_1982,
  title = {Causal {{Analysis}} and {{Latent Class Models}}: {{An Application}} to a {{Communication Hierarchy}} of {{Effects Model}}},
  shorttitle = {Causal {{Analysis}} and {{Latent Class Models}}},
  author = {Madden, Thomas J. and Dillon, William R.},
  date = {1982-11},
  journaltitle = {Journal of Marketing Research},
  shortjournal = {Journal of Marketing Research},
  volume = {19},
  number = {4},
  pages = {472--490},
  issn = {0022-2437, 1547-7193},
  doi = {10.1177/002224378201900409},
  url = {http://journals.sagepub.com/doi/10.1177/002224378201900409},
  urldate = {2024-03-09},
  abstract = {The authors illustrate the use of latent structure analysis to test, in a confirmatory sense, causal hypotheses in an experimental design setting. Two latent factors conceptualized as arousal and yielding are hypothesized to explain the linkages in a communication hierarchy of effects model. A stagewise analysis is proposed which can help in the analysis of multiway tables characterized by cell sparseness. In addition, the analysis addresses the case of polytomous latent factors and polytomous manifest variables.},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/YQ7HQBZR/Madden e Dillon - 1982 - Causal Analysis and Latent Class Models An Applic.pdf}
}

@online{mahajan_empirical_2023,
  title = {Empirical {{Analysis}} of {{Model Selection}} for {{Heterogeneous Causal Effect Estimation}}},
  author = {Mahajan, Divyat and Mitliagkas, Ioannis and Neal, Brady and Syrgkanis, Vasilis},
  date = {2023-06-12},
  eprint = {2211.01939},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2211.01939},
  urldate = {2023-12-25},
  abstract = {We study the problem of model selection in causal inference, specifically for the case of conditional average treatment effect (CATE) estimation under binary treatments. Unlike model selection in machine learning, there is no perfect analogue of cross-validation as we do not observe the counterfactual potential outcome for any data point. Towards this, there have been a variety of proxy metrics proposed in the literature, that depend on auxiliary nuisance models estimated from the observed data (propensity score model, outcome regression model). However, the effectiveness of these metrics has only been studied on synthetic datasets as we can access the counterfactual data for them. We conduct an extensive empirical analysis to judge the performance of these metrics introduced in the literature, and novel ones introduced in this work, where we utilize the latest advances in generative modeling to incorporate multiple realistic datasets. Our analysis suggests novel model selection strategies based on careful hyperparameter tuning of CATE estimators and causal ensembling.},
  pubstate = {preprint},
  keywords = {TR(4)},
  file = {/Users/maxwell.marcos/Zotero/storage/QVRR8RKH/Mahajan et al. - 2023 - Empirical Analysis of Model Selection for Heteroge.pdf;/Users/maxwell.marcos/Zotero/storage/FRT46AFN/2211.html}
}

@article{mena_exploiting_2023,
  title = {Exploiting Time-Varying {{RFM}} Measures for Customer Churn Prediction with Deep Neural Networks},
  author = {Mena, Gary and Coussement, Kristof and De Bock, Koen W. and De Caigny, Arno and Lessmann, Stefan},
  date = {2023-03-21},
  journaltitle = {Annals of Operations Research},
  shortjournal = {Ann Oper Res},
  issn = {0254-5330, 1572-9338},
  doi = {10.1007/s10479-023-05259-9},
  url = {https://link.springer.com/10.1007/s10479-023-05259-9},
  urldate = {2024-04-23},
  abstract = {Abstract             Deep neural network (DNN) architectures such as recurrent neural networks and transformers display outstanding performance in modeling sequential unstructured data. However, little is known about their merit to model customer churn with time-varying data. The paper provides a comprehensive evaluation of the ability of recurrent neural networks and transformers for customer churn prediction (CCP) using time-varying behavioral features in the form of recency, frequency, and monetary value (RFM). RFM variables are the backbone of CCP and, more generally, customer behavior forecasting. We examine alternative strategies for integrating time-varying and non-variant customer features in one network architecture. In this scope, we also assess hybrid approaches that incorporate the outputs of DNNs in conventional CCP models. Using a comprehensive panel data set from a large financial services company, we find recurrent neural networks to outperform transformer architectures when focusing on time-varying RFM features. This finding is confirmed when time-invariant customer features are included, independent of the specific form of feature integration. Finally, we find no statistical evidence that hybrid approaches (based on regularized logistic regression and extreme gradient boosting) improve predictive performance---highlighting that DNNs and especially recurrent neural networks are suitable standalone classifiers for CCP using time-varying RFM measures.},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/39HKU6E9/Mena et al. - 2023 - Exploiting time-varying RFM measures for customer .pdf}
}

@book{mill_system_2020,
  title = {{{SYSTEM OF LOGIC}}},
  author = {MILL, JOHN STUART},
  date = {2020},
  publisher = {SALZWASSER-VERLAG GMBH},
  location = {S.l.},
  isbn = {978-3-7525-0067-7},
  langid = {english},
  annotation = {OCLC: 1198714957}
}

@book{morgan_counterfactuals_2015,
  title = {Counterfactuals and Causal Inference: Methods and Principles for Social Research},
  shorttitle = {Counterfactuals and Causal Inference},
  author = {Morgan, Stephen Lawrence and Winship, Christopher},
  date = {2015},
  series = {Analytical Methods for Social Research},
  edition = {Second edition},
  publisher = {Cambridge University press},
  location = {New York},
  abstract = {"In this second edition of Counterfactuals and Causal Inference, completely revised and expanded, the essential features of the counterfactual approach to observational data analysis are presented with examples from the social, demographic, and health sciences. Alternative estimation techniques are first introduced using both the potential outcome model and causal graphs; after which, conditioning techniques, such as matching and regression, are presented from a potential outcomes perspective. For research scenarios in which important determinants of causal exposure are unobserved, alternative techniques, such as instrumental variable estimators, longitudinal methods, and estimation via causal mechanisms, are then presented. The importance of causal effect heterogeneity is stressed throughout the book, and the need for deep causal explanation via mechanisms is discussed"},
  isbn = {978-1-107-06507-9 978-1-107-69416-3},
  langid = {english}
}

@book{pearl_book_2020,
  title = {The Book of Why: The New Science of Cause and Effect},
  shorttitle = {The Book of Why},
  author = {Pearl, Judea and Mackenzie, Dana},
  date = {2020},
  edition = {First trade paperback edition},
  publisher = {Basic Books},
  location = {New York},
  isbn = {978-0-465-09760-9 978-1-5416-9896-3},
  langid = {english},
  pagetotal = {418},
  file = {/Users/maxwell.marcos/Zotero/storage/GDWHHBM2/Pearl e Mackenzie - 2020 - The book of why the new science of cause and effe.pdf}
}

@book{pearl_causal_2016,
  title = {Causal Inference in Statistics: A Primer},
  shorttitle = {Causal Inference in Statistics},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  date = {2016},
  publisher = {Wiley},
  location = {Chichester, West Sussex},
  isbn = {978-1-119-18684-7},
  pagetotal = {136},
  keywords = {Causation,Mathematical statistics,Probabilities}
}

@article{pearl_consistency_2010,
  title = {On the {{Consistency Rule}} in {{Causal Inference}}: {{Axiom}}, {{Definition}}, {{Assumption}}, or {{Theorem}}?},
  shorttitle = {On the {{Consistency Rule}} in {{Causal Inference}}},
  author = {Pearl, Judea},
  date = {2010-11},
  journaltitle = {Epidemiology},
  volume = {21},
  number = {6},
  pages = {872--875},
  issn = {1044-3983},
  doi = {10.1097/EDE.0b013e3181f5d3fd},
  url = {https://journals.lww.com/00001648-201011000-00019},
  urldate = {2024-03-18},
  langid = {english}
}

@inproceedings{Radcliffe2007UsingCG,
  title = {Using Control Groups to Target on Predicted Lift: {{Building}} and Assessing Uplift Model},
  author = {Radcliffe, Nicholas},
  date = {2007},
  url = {https://api.semanticscholar.org/CorpusID:22535399}
}

@article{rubin_comment_1986,
  title = {Comment: {{Which Ifs Have Causal Answers}}},
  shorttitle = {Comment},
  author = {Rubin, Donald B.},
  date = {1986-12},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {81},
  number = {396},
  pages = {961--962},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1986.10478355},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478355},
  urldate = {2024-03-24},
  langid = {english}
}

@article{rubin_estimating_1974,
  title = {Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.},
  author = {Rubin, Donald B.},
  date = {1974-10},
  journaltitle = {Journal of Educational Psychology},
  shortjournal = {Journal of Educational Psychology},
  volume = {66},
  number = {5},
  pages = {688--701},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/h0037350},
  url = {https://doi.apa.org/doi/10.1037/h0037350},
  urldate = {2024-02-25},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/RFL68E56/Rubin - 1974 - Estimating causal effects of treatments in randomi.pdf}
}

@article{rubin_estimating_1974-1,
  title = {Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.},
  author = {Rubin, Donald B.},
  date = {1974-10},
  journaltitle = {Journal of Educational Psychology},
  shortjournal = {Journal of Educational Psychology},
  volume = {66},
  number = {5},
  pages = {688--701},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/h0037350},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0037350},
  urldate = {2024-02-05},
  langid = {english}
}

@article{rubin_randomization_1980,
  title = {Randomization {{Analysis}} of {{Experimental Data}}: {{The Fisher Randomization Test Comment}}},
  shorttitle = {Randomization {{Analysis}} of {{Experimental Data}}},
  author = {Rubin, Donald B.},
  date = {1980-09},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {75},
  number = {371},
  eprint = {2287653},
  eprinttype = {jstor},
  pages = {591},
  issn = {01621459},
  doi = {10.2307/2287653},
  url = {https://www.jstor.org/stable/2287653?origin=crossref},
  urldate = {2024-03-24}
}

@online{shi_adapting_2019,
  title = {Adapting {{Neural Networks}} for the {{Estimation}} of {{Treatment Effects}}},
  author = {Shi, Claudia and Blei, David M. and Veitch, Victor},
  date = {2019-10-17},
  eprint = {1906.02120},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1906.02120},
  urldate = {2024-03-30},
  abstract = {This paper addresses the use of neural networks for the estimation of treatment effects from observational data. Generally, estimation proceeds in two stages. First, we fit models for the expected outcome and the probability of treatment (propensity score) for each unit. Second, we plug these fitted models into a downstream estimator of the effect. Neural networks are a natural choice for the models in the first step. The question we address is: how can we adapt the design and training of the neural networks used in the first step in order to improve the quality of the final estimate of the treatment effect? We propose two adaptations based on insights from the statistical literature on the estimation of treatment effects. The first is a new architecture, the Dragonnet, that exploits the sufficiency of the propensity score for estimation adjustment. The second is a regularization procedure, targeted regularization, that induces a bias towards models that have non-parametrically optimal asymptotic properties `out-of-the-box`. Studies on benchmark datasets for causal inference show these adaptations outperform existing methods. Code is available at github.com/claudiashi57/dragonnet.},
  pubstate = {preprint},
  file = {/Users/maxwell.marcos/Zotero/storage/KHYA8ZMH/Shi et al. - 2019 - Adapting Neural Networks for the Estimation of Treatment Effects.pdf}
}

@article{splawa-neyman_application_1990,
  title = {On the {{Application}} of {{Probability Theory}} to {{Agricultural Experiments}}. {{Essay}} on {{Principles}}. {{Section}} 9},
  author = {Splawa-Neyman, Jerzy and Dabrowska, D. M. and Speed, T. P.},
  date = {1990-11-01},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {5},
  number = {4},
  issn = {0883-4237},
  doi = {10.1214/ss/1177012031},
  url = {https://projecteuclid.org/journals/statistical-science/volume-5/issue-4/On-the-Application-of-Probability-Theory-to-Agricultural-Experiments-Essay/10.1214/ss/1177012031.full},
  urldate = {2024-02-25},
  file = {/Users/maxwell.marcos/Zotero/storage/BY5TXZW5/Splawa-Neyman et al. - 1990 - On the Application of Probability Theory to Agricu.pdf}
}

@online{toth_active_2022,
  title = {Active {{Bayesian Causal Inference}}},
  author = {Toth, Christian and Lorch, Lars and Knoll, Christian and Krause, Andreas and Pernkopf, Franz and Peharz, Robert and von K\"ugelgen, Julius},
  options = {useprefix=true},
  date = {2022-10-15},
  eprint = {2206.02063},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2206.02063},
  urldate = {2024-01-03},
  abstract = {Causal discovery and causal reasoning are classically treated as separate and consecutive tasks: one first infers the causal graph, and then uses it to estimate causal effects of interventions. However, such a two-stage approach is uneconomical, especially in terms of actively collected interventional data, since the causal query of interest may not require a fully-specified causal model. From a Bayesian perspective, it is also unnatural, since a causal query (e.g., the causal graph or some causal effect) can be viewed as a latent quantity subject to posterior inference -- other unobserved quantities that are not of direct interest (e.g., the full causal model) ought to be marginalized out in this process and contribute to our epistemic uncertainty. In this work, we propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian active learning framework for integrated causal discovery and reasoning, which jointly infers a posterior over causal models and queries of interest. In our approach to ABCI, we focus on the class of causally-sufficient, nonlinear additive noise models, which we model using Gaussian processes. We sequentially design experiments that are maximally informative about our target causal query, collect the corresponding interventional data, and update our beliefs to choose the next experiment. Through simulations, we demonstrate that our approach is more data-efficient than several baselines that only focus on learning the full causal graph. This allows us to accurately learn downstream causal queries from fewer samples while providing well-calibrated uncertainty estimates for the quantities of interest.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/maxwell.marcos/Zotero/storage/DD47JKUY/Toth et al. - 2022 - Active Bayesian Causal Inference.pdf;/Users/maxwell.marcos/Zotero/storage/JD3GZQG4/2206.html}
}

@incollection{van_der_aalst_random_2012,
  title = {Random {{Forests}} for {{Uplift Modeling}}: {{An Insurance Customer Retention Case}}},
  shorttitle = {Random {{Forests}} for {{Uplift Modeling}}},
  booktitle = {Modeling and {{Simulation}} in {{Engineering}}, {{Economics}} and {{Management}}},
  author = {Guelman, Leo and Guill\'en, Montserrat and P\'erez-Mar\'in, Ana M.},
  editor = {Engemann, Kurt J. and Gil-Lafuente, Anna M. and Merig\'o, Jos\'e M.},
  editora = {Van Der Aalst, Wil and Mylopoulos, John and Rosemann, Michael and Shaw, Michael J. and Szyperski, Clemens},
  editoratype = {redactor},
  date = {2012},
  volume = {115},
  pages = {123--133},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-30433-0_13},
  url = {http://link.springer.com/10.1007/978-3-642-30433-0_13},
  urldate = {2024-05-28},
  isbn = {978-3-642-30432-3 978-3-642-30433-0}
}

@article{vanderweeleCausalInferenceMultiple2013,
  title = {Causal Inference under Multiple Versions of Treatment},
  author = {VanderWeele, Tyler J. and Hernan, Miguel A.},
  date = {2013-05-29},
  journaltitle = {Journal of Causal Inference},
  volume = {1},
  number = {1},
  pages = {1--20},
  issn = {2193-3685, 2193-3677},
  doi = {10.1515/jci-2012-0002},
  url = {https://www.degruyter.com/document/doi/10.1515/jci-2012-0002/html},
  urldate = {2024-02-07},
  abstract = {Abstract               : In this article, we discuss causal inference when there are multiple versions of treatment. The potential outcomes framework, as articulated by Rubin, makes an assumption of no multiple versions of treatment, and here we discuss an extension of this potential outcomes framework to accommodate causal inference under violations of this assumption. A variety of examples are discussed in which the assumption may be violated. Identification results are provided for the overall treatment effect and the effect of treatment on the treated when multiple versions of treatment are present and also for the causal effect comparing a version of one treatment to some other version of the same or a different treatment. Further identification and interpretative results are given for cases in which the version precedes the treatment as when an underlying treatment variable is coarsened or dichotomized to create a new treatment variable for which there are effectively ``multiple versions''. Results are also given for effects defined by setting the version of treatment to a prespecified distribution. Some of the identification results bear resemblance to identification results in the literature on direct and indirect effects. We describe some settings in which ignoring multiple versions of treatment, even when present, will not lead to incorrect inferences.},
  file = {/Users/maxwell.marcos/Zotero/storage/2SI26F8X/VanderWeele e Hernan - 2013 - Causal inference under multiple versions of treatm.pdf;/Users/maxwell.marcos/Zotero/storage/KG8XLGGU/VanderWeele e Hernan - 2013 - Causal inference under multiple versions of treatm.pdf}
}

@inproceedings{yuanStateTransitionModel2019,
  title = {A {{State Transition Model}} for {{Mobile Notifications}} via {{Survival Analysis}}},
  booktitle = {Proceedings of the {{Twelfth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Yuan, Yiping and Zhang, Jing and Chatterjee, Shaunak and Yu, Shipeng and Rosales, Romer},
  date = {2019-01-30},
  pages = {123--131},
  publisher = {ACM},
  location = {Melbourne VIC Australia},
  doi = {10.1145/3289600.3290981},
  url = {https://dl.acm.org/doi/10.1145/3289600.3290981},
  urldate = {2024-01-26},
  eventtitle = {{{WSDM}} '19: {{The Twelfth ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  isbn = {978-1-4503-5940-5},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/EQYG6EEP/Yuan et al. - 2019 - A State Transition Model for Mobile Notifications .pdf}
}

@article{yule_investigation_1899,
  title = {An {{Investigation}} into the {{Causes}} of {{Changes}} in {{Pauperism}} in {{England}}, {{Chiefly During}} the {{Last Two Intercensal Decades}} ({{Part I}}.)},
  author = {Yule, G. Udny},
  date = {1899-06},
  journaltitle = {Journal of the Royal Statistical Society},
  shortjournal = {Journal of the Royal Statistical Society},
  volume = {62},
  number = {2},
  eprint = {10.2307/2979889},
  eprinttype = {jstor},
  pages = {249},
  issn = {09528385},
  doi = {10.2307/2979889},
  url = {https://www.jstor.org/stable/10.2307/2979889?origin=crossref},
  urldate = {2024-02-24},
  file = {/Users/maxwell.marcos/Zotero/storage/Y3M4DLPZ/Yule - 1899 - An Investigation into the Causes of Changes in Pau.pdf}
}

@article{zhan_weighted_2024,
  title = {Weighted Doubly Robust Learning: {{An}} Uplift Modeling Technique for Estimating Mixed Treatments' Effect},
  shorttitle = {Weighted Doubly Robust Learning},
  author = {Zhan, Baoqiang and Liu, Chao and Li, Yongli and Wu, Chong},
  date = {2024-01},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  volume = {176},
  pages = {114060},
  issn = {01679236},
  doi = {10.1016/j.dss.2023.114060},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923623001355},
  urldate = {2024-04-19},
  langid = {english}
}

@article{zhang_unified_2022,
  title = {A {{Unified Survey}} of {{Treatment Effect Heterogeneity Modelling}} and {{Uplift Modelling}}},
  author = {Zhang, Weijia and Li, Jiuyong and Liu, Lin},
  date = {2022-11-30},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {54},
  number = {8},
  pages = {1--36},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3466818},
  url = {https://dl.acm.org/doi/10.1145/3466818},
  urldate = {2024-03-24},
  abstract = {A central question in many fields of scientific research is to determine how an outcome is affected by an action, i.e., to estimate the causal effect or treatment effect of an action. In recent years, in areas such as personalised healthcare, sociology, and online marketing, a need has emerged to estimate heterogeneous treatment effects with respect to individuals of different characteristics. To meet this need, two major approaches have been taken: treatment effect heterogeneity modelling and uplifting modelling. Researchers and practitioners in different communities have developed algorithms based on these approaches to estimate the heterogeneous treatment effects. In this article, we present a unified view of these two seemingly disconnected yet closely related approaches under the potential outcome framework. We provide a structured survey of existing methods following either of the two approaches, emphasising their inherent connections and using unified notation to facilitate comparisons. We also review the main applications of the surveyed methods in personalised marketing, personalised medicine, and sociology. Finally, we summarise and discuss the available software packages and source codes in terms of their coverage of different methods and applicability to different datasets, and we provide general guidelines for method selection.},
  langid = {english},
  file = {/Users/maxwell.marcos/Zotero/storage/N2V7PU86/Zhang et al. - 2022 - A Unified Survey of Treatment Effect Heterogeneity.pdf}
}
